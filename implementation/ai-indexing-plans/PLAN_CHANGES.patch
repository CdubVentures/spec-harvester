--- a/ADDENDUM-field-studio-overlooked-items.md
+++ b/ADDENDUM-field-studio-overlooked-items.md
@@ -1,4 +1,4 @@
-﻿# Field Studio Overlooked Items Addendum (Phase-mapped)

+# Field Studio Overlooked Items Addendum (Phase-mapped)

 

 Goal: add high-value Field Studio wiring that improves accuracy, explainability, and runtime efficiency.

 

@@ -116,6 +116,25 @@
 Why this helps:

 - Prevents control-plane drift and ensures every visible knob has a purpose.

 

+## H) Cross-cutting: identity lock + applicability guardrails (new)

+Add Studio-level support for **identity safety**, so the system can prove it indexed the *correct exact model/variant*.

+

+Add to Studio schema (conceptual knobs; map to compiled rules):

+- `identity.required_tokens`: e.g., `["brand","model"]` (+`sku` when present)

+- `identity.variant_tokens`: optional list of tokens/suffixes that define a spec-relevant variant (region codes, P/N)

+- `identity.allow_multi_model_sources`: default false for deep/critical fields

+

+Phase mapping:

+- Phase 01: compute and display `IdentityLockState` and block deep fields until locked

+- Phase 02/03: use `variant_tokens` as guard terms and triage boosts

+- Phase 06/07: persist/apply doc applicability metadata (`identity_match_level`, `applies_to_item_score`)

+- Phase 08: enforce `unknown_reason="identity_uncertain"` when identity is not locked or evidence is non-applicable

+- Phase 09: convergence loop prioritizes identity locking before deep-field rounds

+

+GUI proof:

+- A visible **Identity Locked** badge with evidence snippet_ids.

+- Prime Sources list shows applicability badges and filters out non-applicable evidence for deep fields.

+

 ## Acceptance Criteria (Addendum)

 

 - Field Studio search_hints materially changes emitted queries and is visible in GUI provenance.


--- a/PHASE-01-needset-engine.md
+++ b/PHASE-01-needset-engine.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 01 â€” Field state snapshot + NeedSet engine (tier + confidence aware)

+# Phase 01 — Field state snapshot + NeedSet engine (tier + confidence aware)

 

 

 ## Goal

@@ -38,7 +38,7 @@
 ## Deliverables

 - `NeedSetEngine` module

 - persisted NeedSet snapshots per run

-- GUI â€œNeedSetâ€ panel/table (sortable, with reason badges)

+- GUI “NeedSet panel/table (sortable, with reason badges)

 

 ## Implementation

 

@@ -46,7 +46,7 @@
 Pull per-field state from your existing pipeline outputs (preferred order):

 1) latest consensus/selection outputs in `runProduct.js` artifacts

 2) SpecDb if you persist field states there (`src/db/specDb.js`)

-3) fallback: compute â€œmissingâ€ from normalized output

+3) fallback: compute “missing from normalized output

 

 Field state schema (in-memory):

 ```ts

@@ -60,6 +60,8 @@
   best_tier_seen: 1|2|3|4|null;

   tier_preference: number[]; // e.g., [1,2]

   conflict: boolean;

+  blocked_by: string[]; // e.g. ["identity_unlocked","publish_gate_block"]

+  best_identity_match: 'none'|'partial'|'exact'|null; // optional (Phase 03/04 signals)

 }

 ```

 

@@ -83,8 +85,8 @@
 - `["missing","tier_deficit","min_refs_fail","conflict","low_conf"]`

 

 ### 1.3 Where to integrate

-- Add `computeNeedSet(...)` at the end of each â€œroundâ€ of your run loop.

-- If you donâ€™t have explicit rounds yet, compute once after the first extraction/consensus and again after each discovery+index increment (Phase 9 adds explicit rounds).

+- Add `computeNeedSet(...)` at the end of each “round of your run loop.

+- If you don’t have explicit rounds yet, compute once after the first extraction/consensus and again after each discovery+index increment (Phase 9 adds explicit rounds).

 

 Likely touchpoints:

 - `src/pipeline/runProduct.js` (after consensus + validation)

@@ -103,6 +105,52 @@
 - Read evidence.tier_preference, evidence.min_evidence_refs, and priority.publish_gate per field from compiled rules.

 - Add NeedSet reason tags for policy gaps: tier_pref_unmet, min_refs_fail, publish_gate_block.

 - Persist policy snapshot per row so Phase 09 can explain planner choices deterministically.

+

+### 1.6 Identity lock + applicability gating (must)

+Deep/spec fields are only meaningful if we are indexing the **correct exact model/variant**.

+Add an explicit, auditable **IdentityLockState** computed each round and exposed in the GUI.

+

+Run-level identity state (persist alongside NeedSet):

+```ts

+type IdentityLockState = {

+  fingerprint: string; // stable hash of normalized brand+model+sku(+variant tokens)

+  status: 'unlocked'|'provisional'|'locked';

+  conflict: boolean;

+  locked_by: Array<{

+    tier: 1|2|3|4;

+    doc_id: string;

+    snippet_ids: string[]; // evidence refs that explicitly name the model/SKU

+    note?: string;

+  }>;

+}

+```

+

+Locking rules (rules-first; no guessing):

+- **Locked** when either:

+  1) a Tier‑1 manual/spec/support source explicitly confirms brand+model (and SKU if present), **or**

+  2) two independent sources (distinct domains/doc_ids) explicitly confirm identity with no conflicts.

+- **Conflict** when:

+  - competing model/SKU tokens are present across candidate evidence, or

+  - a high-ranked document is a multi-model comparison/spec table and variant resolution is unclear.

+

+NeedSet behavior:

+- Identity fields (`required_level='identity'`) always rank first.

+- If identity is not locked, mark deep/critical fields as blocked:

+  - `blocked_by += ["identity_unlocked"]`

+  - reason tags include: `identity_unlocked`, `blocked_by_identity`

+- Planner (Phase 09) must schedule **identity-lock discovery** (Tier‑1 targets) before attempting deep-field convergence.

+

+Applicability signals:

+- Phase 03/04/06 will emit doc/applicability hints (exact/partial/none) and multi-model flags.

+- Store a per-field `best_identity_match` so the GUI can show whether accepted values came from **exact-match** evidence.

+

+Persistence:

+- `artifacts/<run_id>/identity_lock.json`

+- `artifacts/<run_id>/needset.json` includes a summary `{ identity_lock: {status,fingerprint,conflict} }`

+

+GUI proof additions:

+- NeedSet header badge: **Identity: Unlocked / Provisional / Locked**

+- Clicking the badge shows locking evidence snippet_ids and their source URLs.

 

 ## GUI proof

 ### Required GUI panels


--- a/PHASE-02-searchprofile-aliases.md
+++ b/PHASE-02-searchprofile-aliases.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,18 +22,18 @@
 

 ---

 

-# Phase 02 â€” Deterministic aliases + optional Flashâ€‘Lite SearchProfile JSON

+# Phase 02 — Deterministic aliases + optional Flash‑Lite SearchProfile JSON

 

 

 ## Goal

-Create a stable **SearchProfile** (aliases + query templates) per run, so discovery is reproducible and doesnâ€™t devolve into random alias loops.

+Create a stable **SearchProfile** (aliases + query templates) per run, so discovery is reproducible and doesn’t devolve into random alias loops.

 

 ## Deliverables

 - Deterministic alias generator (always on)

-- Optional LLM-assisted SearchProfile generator (Flashâ€‘Lite)

+- Optional LLM-assisted SearchProfile generator (Flash‑Lite)

 - Validation + caps (prevent hallucinated model/SKU)

 - Persisted `search_profile.json`

-- GUI â€œSearch Profileâ€ view

+- GUI “Search Profile view

 

 ## Implementation

 

@@ -42,9 +42,22 @@
 - normalize whitespace, punctuation

 - generate spacing/hyphen variants:

   - `AW610M`, `AW 610M`, `AW-610M`

-- preserve digit groups (NEVER mutate â€œ610â€ â†’ â€œ61â€)

+- preserve digit groups (NEVER mutate “610 → “61)

 - include brand-only and brand+model combos

-- cap to 8â€“12 aliases

+- cap to 8–12 aliases

+

+#### 2.1.1 Identity fingerprint + variant guard terms (always)

+In addition to aliases, compute a **run-stable identity fingerprint** and a small set of guard terms that prevent cross-variant contamination.

+

+- `identity_fingerprint` = sha1(normalized brand + "|" + normalized model + "|" + normalized sku + "|" + normalized variant tokens)

+  - variant tokens include region suffixes (e.g., `-EU`, `-US`), colorways *only if they change specs*, and manufacturer P/N when available.

+- `variant_guard_terms` (capped to 3–6):

+  - exact model token (quoted form for short models)

+  - SKU / P/N tokens when present

+  - one or two distinctive tokens from the official title line (e.g., "wireless", "4K", "AMOLED") **only if** they reduce ambiguity

+

+These are stored in `search_profile.json` and reused by Phase 03 triage and Phase 07 applicability checks.

+

 

 Store:

 ```json

@@ -70,6 +83,7 @@
 ```json

 {

   "identity_aliases": ["..."],

+  "variant_guard_terms": ["..."],

   "negative_terms": ["case","skins","bundle"],

   "doc_hint_queries": [

     { "doc_hint":"manual_pdf", "queries":["..."] },

@@ -91,6 +105,13 @@
   - doc_hint queries <= 3 per hint

   - field_target queries <= 3 per field

 - duplicates after normalization

+

+- introduces a different model/SKU token not in the seed identity or deterministic aliases

+- for short/ambiguous models (e.g., <=4 chars or mostly numeric), emits an unquoted model token (force `"MODEL"` form)

+- for Tier‑1 doc hints, omits all `variant_guard_terms` when they exist (guard terms must appear in at least one query per doc_hint)

+- contains multiple distinct model tokens (mark as `multi_model_query` and require Phase 03 applicability confirmation)

+

+

 

 ### 2.4 Integration points

 - `src/search/queryBuilder.js` and/or `src/research/queryPlanner.js` should accept SearchProfile rather than ad-hoc strings.


--- a/PHASE-03-provider-search-triage.md
+++ b/PHASE-03-provider-search-triage.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 03 â€” Provider search + SERP logging + tier/doc_kind tagging + triage (Google/SearXNG)

+# Phase 03 — Provider search + SERP logging + tier/doc_kind tagging + triage (Google/SearXNG)

 

 

 ## Goal

@@ -40,7 +40,7 @@
 - SERP logging tables (or artifacts) + dedupe

 - Tier/doc_kind tagging

 - Triage strategy (rules-first; optional fast model rerank)

-- GUI: â€œSERP Explorerâ€ table per query

+- GUI: “SERP Explorer table per query

 - Config files:

   - `searxng/settings.yml`

   - `docker/docker-compose.observability.yml` (optional local SearXNG)

@@ -59,9 +59,9 @@
 

 ### 3.2 Query emission

 From SearchProfile (Phase 2), emit queries grouped by doc_hint:

-- Tierâ€‘1 hunting:

+- Tier‑1 hunting:

   - `manual_pdf`, `spec_pdf`, `official_support`

-- Tierâ€‘2 hunting:

+- Tier‑2 hunting:

   - `lab_review`, `teardown_review`

 Only emit doc_hints relevant to the current NeedSet.

 

@@ -76,17 +76,37 @@
 - doc_kind_guess:

   - pdf if url endswith .pdf or content-type hints

   - support if path includes /support/ /downloads/

-  - review/teardown if title/snippet contains â€œreviewâ€, â€œteardownâ€, â€œdisassemblyâ€

+  - review/teardown if title/snippet contains "review", "teardown", "disassembly"

+

+Identity/applicability hints (rules-first; cheap):

+- `identity_match_level`:

+  - `exact` if brand token + full model token (or a deterministic alias) appears in title/snippet/URL path

+  - `partial` if brand token appears and a shortened/partial model token appears

+  - `none` otherwise

+- `variant_guard_hit`: true if any Phase‑02 `variant_guard_terms` appear in title/snippet

+- `multi_model_hint`: true if title/snippet strongly suggests a multi-model page:

+  - contains "vs", "comparison", "compatible with", "fits", "works with"

+  - contains multiple distinct model-like tokens (regex heuristic; cap captures)

+- `other_model_tokens` (capped, for audit/debug only): model-like tokens found that do NOT match our identity aliases

+

+These hints are persisted for audit and reused later by Phase 04/06 (URL health + document applicability scoring).

 

 Persist candidate with:

 - rank, title, snippet, tier_guess, doc_kind_guess

+- identity_match_level, variant_guard_hit, multi_model_hint

+- other_model_tokens (capped) + reason_tags

 

 ### 3.4 Triage (fetch selection)

-Goal: pick K URLs per run (K=8â€“15) weighted by NeedSet.

+Goal: pick K URLs per run (K=8–15) weighted by NeedSet.

+If Phase 01 reports `IdentityLockState.status != 'locked'`, bias selection toward Tier‑1 identity‑confirming docs (manual/spec/support) with **exact** identity match before chasing deep fields.

 Rules-first scoring:

 - + tier weight (tier1>tier2>tier3)

 - + doc_kind match for doc_hint

 - + brand/model token match in title/snippet

+

+- + exact identity_match_level bonus (exact > partial > none)

+- + variant_guard_hit bonus (prevents cross-variant drift)

+- - multi_model_hint penalty (unless the NeedSet explicitly calls for comparison/compatibility evidence)

 - + pdf bonus for manual/spec hints

 - - denied/low-quality hosts (use `isDeniedHost(...)`)

 - - duplicates / near-duplicates (use `src/search/serpDedupe.js`)

@@ -96,7 +116,7 @@
 ### 3.5 GUI proof

 Add a SERP view:

 - group by query_text

-- show each candidate: url, tier, doc_kind, score, triage decision, reason badges

+- show each candidate: url, tier, doc_kind, identity_match_level, multi_model_hint, score, triage decision, reason badges

 

 Add counters:

 - candidates_checked

@@ -179,6 +199,6 @@
 

 ## Exit criteria

 - Every search query and candidate is visible in the GUI.

-- Selected URLs are dominated by Tierâ€‘1 and Tierâ€‘2 when high-stakes fields require them.

+- Selected URLs are dominated by Tier‑1 and Tier‑2 when high-stakes fields require them.

 - Phase 03 artifacts contain all fields needed by Phase 06B without adding scheduler logic here.

 


--- a/PHASE-05-parallel-fetch-parse.md
+++ b/PHASE-05-parallel-fetch-parse.md
@@ -56,6 +56,12 @@
 - on 429/403: drop to 1 and extend delay

 - on repeated blocks: cooldown host via url_health and temporarily skip

 

+Note:

+- The host limiter should consult Phase‑04 `url_health` before starting a fetch:

+  - if `cooldown_until > now`, delay/skip the job and record the skip reason

+  - use host-level budget signals (e.g., reduced concurrency after 429/blocked)

+- **Phase 05 owns in-run throttling.** Long-term retry/repair cadence is owned by **Phase 06B**.

+

 ### 5.3 HTTP-first + escalation

 Fetch decision:

 1) Try `HttpFetcher`


--- a/PHASE-06B-refetch-scheduler.md
+++ b/PHASE-06B-refetch-scheduler.md
@@ -1,4 +1,4 @@
-# Deep Spec Harvester - Phased Implementation Plan (Accuracy-Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an implementation prompt for senior software engineers.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and GUI proof.

@@ -56,6 +56,23 @@
 ## Implementation

 

 ### 06B.1 Queue + worker contract

+#### 06B.1.1 Queue schema alignment (must decide early)

+`schema_v1.sql` currently includes `job_actions` (good as an append-only audit log), while this phase describes a `jobs` queue.

+

+Pick one of these and implement it explicitly:

+

+**Option A (recommended):** stateful `jobs` + append-only `job_actions`

+- `jobs` is the live queue/state machine (`queued → running → done/failed/cooldown`)

+- `job_actions` records every transition and worker result (for replay/debug)

+

+**Option B (acceptable for v1):** extend `job_actions` to act as the queue

+- add: `scheduled_at`, `priority`, `status`, `attempt_count`, `dedupe_key`, `locked_by_worker`

+- enforce “one active row per dedupe_key” via unique index or transactional check

+

+Regardless of option:

+- `dedupe_key` should include **identity_fingerprint** + job_type + (domain/doc_kind/field_targets) so equivalent work is bounded across runs.

+- GUI must show job lifecycle transitions with timestamps so automation is provable.

+

 Persist jobs with minimal required fields:

 - `job_id`, `job_type`, `priority`, `status`

 - `category`, `product_id`, `field_targets`

@@ -83,7 +100,17 @@
 ### 06B.3 Staleness refresh loop (TTL + hash-aware)

 Input signals:

 - indexed docs with age > TTL window

-- optional domain/doc_kind-specific TTL policy.

+- a domain/doc_kind-specific TTL policy table (explicit, testable).TTL policy (make it explicit):

+- Represent as config or DB table `ttl_policies`:

+  - `domain_pattern` (or host), `doc_kind`, `tier` (optional)

+  - `ttl_days`, `jitter_pct` (avoid stampedes), `max_refresh_per_day`

+- Suggested defaults (tune later):

+  - Tier‑1 manual/spec PDF: 180 days

+  - official support/download pages: 90 days

+  - Tier‑2 lab reviews: 365 days

+  - Tier‑3/4 general pages: 30–60 days

+

+

 

 Policy:

 - enqueue refresh fetch jobs

@@ -98,6 +125,10 @@
 - NeedSet tier/min_refs/confidence deficits from Phase 09.

 

 Policy:

+

+- if Phase 01 reports `IdentityLockState.status != 'locked'`:

+  - emit **identity-lock** discovery jobs first (Tier‑1 manual/spec/support + SKU/P‑N queries)

+  - delay deep-field rediscovery unless it is strictly identity-confirming (prevents wrong-variant contamination)

 - emit targeted discovery jobs by deficit reason:

   - tier deficit -> Tier 1 doc hints first

   - min refs fail -> diversify domains/doc kinds

@@ -122,7 +153,7 @@
 ### 06B.6 GUI proof

 Add `Automation Queue` view:

 - queued/running/failed counts by `job_type`

-- per-job `source_signal`, `dedupe_key`, next run time

+- per-job `source_signal`, `dedupe_key` (includes identity_fingerprint), next run time

 - recent actions feed (`repair`, `refresh`, `rediscovery`)

 

 Required proof scenarios:


--- a/PHASE-06-evidence-index-db.md
+++ b/PHASE-06-evidence-index-db.md
@@ -33,6 +33,7 @@
 

 ## Deliverables

 - SQLite DDL: `sql/schema_v1.sql` (included in this bundle)

+- **Recommended migration for true dedupe**: add a shared `doc_content` layer keyed by `content_hash` + per-run `doc_instances`/links (documented below)

 - `src/index/evidenceIndexDb.js` (new)

 - Parsing adapters emit:

   - chunks (text snippets)

@@ -57,9 +58,40 @@
   - `searchChunksFTS(query, opts)`

   - `searchFactsFTS(query, opts)`

 

+### 6.1.1 Data model: shared content (by hash) vs per-run instances (important)

+The current `schema_v1.sql` scopes `documents/chunks/facts` by `run_id`, which is simple but makes true cross-run dedupe awkward.

+

+**Recommended (dedupe-correct) approach:**

+- Treat `content_hash` as the durable identity of fetched content.

+- Store parsed artifacts once per `content_hash` (shared content layer).

+- Create a per-run “instance/link” row that points to the shared content.

+

+Conceptually:

+

+- `doc_content(content_hash PK, storage_key, parsed_ok, parser_version, chunker_version, ...)`

+- `doc_instances(doc_instance_id PK, run_id, item_id, url, final_url, domain, tier, doc_kind, content_hash FK, fetch_id, created_at, ...)`

+- `chunks(content_hash FK, snippet_id PK, chunk_index, start_offset, end_offset, text, text_hash, ...)`

+- `facts(content_hash FK, fact_id PK, k, v, unit, raw, snippet_id FK?, ...)`

+

+Why this matters:

+- Phase 06 “skip parse+index on hash hit” becomes **real** (no duplicated chunks/FTS rows).

+- snippet_ids remain stable across runs even when URLs change (mirrors/redirects).

+- retrieval can operate on shared chunks/facts while still attributing usage to the current run/item.

+

+**If you keep schema_v1 for the first milestone:**

+- On `content_hash` hit, either:

+  1) copy chunks/facts into the new run (fast but duplicates DB), or

+  2) change retrieval queries to look up by `content_hash` instead of `run_id`.

+- Do not claim “true dedupe” until one of the above is implemented and proven in GUI.

+

+This phase’s GUI proof should explicitly show which dedupe strategy is active.

+

 ### 6.2 Stable snippet_id rules

 snippet_id must be deterministic:

-- `snippet_id = sha1(final_url + ":" + start_offset + ":" + end_offset + ":" + text_hash_prefix)`

+- **Recommended** (stable across mirrors/refetches):

+  - `snippet_id = sha1(content_hash + ":" + snippet_schema_version + ":" + chunker_version + ":" + chunk_index + ":" + text_hash_prefix)`

+- Store `chunk_index` plus offsets for debugging and highlighting.

+- Persist `parser_version`, `chunker_version`, and `snippet_schema_version` so future parser upgrades don’t silently break evidence refs.

 Store both `snippet_id` and `text_hash`.

 

 ### 6.3 Parsing integration

@@ -74,15 +106,47 @@
 Adaptors:

 - You already have adapters in `src/adapters/` and table parsing helpers.

 

-### 6.4 Dedupe

-Before parsing/indexing:

-- if `content_hash` exists and parsed_ok=true:

-  - skip parse+index and link the existing doc to the new run (optional)

-- Always still update url_health and url_memory stats (Phase 10).

+### 6.3.1 Document applicability metadata (identity safety)

+To prevent wrong-model contamination, compute and persist cheap applicability metadata during indexing.

+

+Per document (doc_content or document row), store:

+- `identity_match_level`: `exact|partial|none`

+- `multi_model_detected`: boolean

+- `applies_to_item_score`: 0.0–1.0 (rules-first)

+- `competing_model_tokens` (capped) for audit/debug

+

+Rules-first scoring suggestions:

+- exact match if (brand + full model token) appears in:

+  - document title/header, **or**

+  - the same table header/row as key anchors (e.g., "Model", "Part Number")

+- partial match if brand present but model appears only once in body or as "compatible with"

+- multi-model if multiple model-like tokens are present near spec tables, or the page is a comparison

+

+Phase 07 retrieval must be able to filter/boost by these fields.

+GUI proof: show applicability badges next to indexed docs and next to prime source snippets.

+

+### 6.4 Dedupe + linking behavior (must be explicit)

+Before parsing/indexing, always record the fetch outcome, then decide reuse:

+

+1) **Always** insert/update the `fetches` row (you want url_health + observability even on dedupe hits).

+2) Compute `content_hash` and look up existing indexed content:

+   - if `content_hash` exists and `parsed_ok=true`:

+     - **shared-content mode (recommended):** create a `doc_instance`/link row for this run that points to the existing `content_hash` and **do not** duplicate chunks/facts/FTS rows.

+     - **schema_v1 fallback:** either copy chunks/facts into the new run *or* make retrieval query by `content_hash` instead of `run_id`. Pick one and prove it in GUI.

+   - if missing or `parsed_ok=false`:

+     - parse + index, then mark `parsed_ok=true`.

+

+Always:

+- update Phase‑04 `url_health` and Phase‑10 `url_memory`/learning signals

+- emit a run event that records the dedupe outcome:

+  - `dedupe_hit: true|false`

+  - `reuse_mode: shared|copied|none`

 

 ### 6.5 GUI proof

 - Index inventory table:

   - doc_kind, tier, domain, chunks_count, facts_count, parsed_ok

+  - content_hash (short), dedupe_hit/reuse_mode

+  - identity_match_level, multi_model_detected

 - Index search box:

   - query “PAW3395” and get hits with snippet previews and links.

 


--- a/PHASE-07-tier-retrieval-prime-sources.md
+++ b/PHASE-07-tier-retrieval-prime-sources.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 07 â€” Tier-aware internal retrieval + Prime Sources builder

+# Phase 07 — Tier-aware internal retrieval + Prime Sources builder

 

 

 ## Goal

@@ -38,13 +38,26 @@
 

 ## Implementation

 

-### 7.1 Retrieval ranking

-Rank candidate snippets/facts by:

-- tier weight: tier1=3, tier2=2, tier3=1

-- doc_kind alignment: manual/spec > support > lab_review > general

-- identity match: brand+model tokens near the snippet

-- anchor proximity: field_anchors matched in same snippet or same table row

+### 7.1 Retrieval ranking (tier + applicability aware)

+Rank candidate snippets/facts by (highest first):

+- tier weight (tier1 > tier2 > tier3), then apply per-field `evidence.tier_preference` boosts

+- doc_kind alignment: manual/spec > official support > lab_review/teardown > general

+- **applicability** (identity safety):

+  - `applies_to_item_score` (Phase 06) and `identity_match_level` (`exact > partial > none`)

+  - `variant_guard_hit` bonus when available (Phase 03 hint)

+  - `multi_model_detected` / `multi_model_hint` penalty (unless the field explicitly targets compatibility/comparison)

+- anchor proximity: field_anchors matched in the same snippet or table row

+- unit + parse-template cues (Hz, mm, g, etc.)

 - recency (optional)

+

+Hard filters (contract-driven):

+- If `IdentityLockState.status != 'locked'`:

+  - only retrieve snippets that can help **lock identity** (brand/model/SKU/P‑N anchors)

+  - do not assemble deep-field prime sources yet (prevents wrong-variant contamination)

+- For `required_level in {identity, critical}`:

+  - require `identity_match_level != none`

+- For deep/critical fields after identity is locked:

+  - require `applies_to_item_score >= 0.7` OR (Tier‑1 manual/spec with `identity_match_level=exact`)

 

 ### 7.2 Field anchors usage

 For each field_key:

@@ -57,18 +70,25 @@
 - pick top snippets until:

   - `min_refs` satisfied

   - if distinct-sources required: ensure different domains/doc_ids

+

+- enforce applicability for selected snippets:

+  - for deep/critical fields, prefer `identity_match_level=exact` and `applies_to_item_score` above threshold

+  - avoid `multi_model_detected=true` documents unless the field explicitly targets compatibility/comparison

+- if identity is not locked:

+  - build prime sources only for identity-locking fields

+  - return empty prime sources for deep fields and mark them `blocked_by_identity` (Phase 01 NeedSet will reflect this)

 - persist to `prime_sources` table

 - ensure snippet_ids exist (no dangling refs)

 

 ### 7.4 GUI proof

 - Field view shows:

-  - retrieval hits (tier/doc_kind/url/snippet preview)

+  - retrieval hits (tier/doc_kind/url/snippet preview, identity_match_level, applies_to_item_score)

   - selected prime sources and whether min_refs satisfied

-  - reason badges (tier_preferred, anchor_match, table_fact)

+  - reason badges (tier_preferred, identity_exact, applicability_high, anchor_match, table_fact)

 

 Proof steps:

 - pick a mouse missing polling_rate:

-  - retrieval should find â€œ8000 Hzâ€ in manual/spec

+  - retrieval should find “8000 Hz in manual/spec

   - prime sources should include >=2 refs if required

 

 ### 7.5 Field Studio tier preference wiring (overlooked)


--- a/PHASE-08-extraction-context-wiring.md
+++ b/PHASE-08-extraction-context-wiring.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 08 â€” Extraction Context Matrix wiring into prompts + extraction dashboard

+# Phase 08 — Extraction Context Matrix wiring into prompts + extraction dashboard

 

 

 ## Goal

@@ -33,7 +33,7 @@
 - include component refs (capped)

 - include Prime Sources snippets (stable snippet_id)

 

-Also: add an â€œExtractionâ€ dashboard tab that proves extraction is grounded and valid.

+Also: add an “Extraction dashboard tab that proves extraction is grounded and valid.

 

 ## Deliverables

 - `ExtractionContextAssembler` module (new or integrated into `extractCandidatesLLM.js`)

@@ -48,34 +48,53 @@
 

 ## Implementation

 

-### 8.1 Contract assembly

-For each field:

+### 8.1 Contract + identity assembly

+For each field, assemble **contract + policy + identity gating** context:

+

 - type/shape/unit/range

 - list rules (dedupe/order/max_items)

 - evidence policy:

   - required? min_refs? tier preference?

   - distinct sources required?

+- identity/applicability context (from Phase 01 + Phase 06):

+  - `IdentityLockState.status` + `identity_fingerprint`

+  - normalized identity tokens: brand, model, sku (if present)

+  - `blocked_by` flags from NeedSet (e.g., `identity_unlocked`, `publish_gate_block`)

+  - applicability requirements for this field (e.g., deep/critical fields require exact identity match)

 - parse template intent:

-  - template id + 1â€“2 examples (avoid raw regex dumps)

+  - template id + 1–2 examples (avoid raw regex dumps)

 

-### 8.2 Evidence payload

+### 8.2 Evidence payload (Prime Sources)

 For each field in a batch:

-- attach Prime Sources:

+- attach Prime Sources (selected in Phase 07):

   - snippet_id

   - url

-  - tier

+  - tier + doc_kind

+  - **applicability metadata**: identity_match_level, applies_to_item_score, multi_model_detected

   - short quote (<= ~300 chars)

 - keep batch context compact; do NOT dump entire pages.

 

-### 8.3 Strict output contract

+If `IdentityLockState.status != 'locked'`, only include Prime Sources for identity-locking fields. For all other fields, the extractor should return `unknown` with `unknown_reason="identity_uncertain"` (see below).

+

+### 8.3 Strict output contract (with identity-safe unknowns)

 Extraction outputs MUST include:

-- value (or unknown)

+- value (or unknown token)

 - snippet_id refs array

 - unknown_reason (enum)

+

+Required unknown reasons (minimum set; extend as needed):

+- `missing_evidence`

+- `conflict`

+- `identity_uncertain` (identity not locked or evidence not applicable)

+- `blocked_by_policy` (e.g., publish gate)

+

 Reject on:

 - refs referencing unknown snippet_id

 - schema mismatch

 - enum out of set

+- **identity safety violation**:

+  - value is present but referenced snippets come from docs with `identity_match_level='none'`, or

+  - for deep/critical fields, referenced docs fail applicability thresholds (e.g., `applies_to_item_score < 0.7`)

 

 ### 8.4 GUI proof

 Extraction tab panels:

@@ -84,6 +103,7 @@
   - schema_fail_rate

   - evidence_policy_violation_rate

   - dangling_snippet_ref_rate

+  - identity_uncertain_rate

   - extracted_fields_per_min

 

 Proof steps:


--- a/PHASE-09-convergence-loop-stop.md
+++ b/PHASE-09-convergence-loop-stop.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 09 â€” Tier/confidence convergence loop + stop conditions (no infinite key/alias loops)

+# Phase 09 — Tier/confidence convergence loop + stop conditions (no infinite key/alias loops)

 

 

 ## Goal

@@ -34,7 +34,7 @@
 - stop if marginal yield is low

 

 ## Deliverables

-- Explicit â€œroundâ€ loop in orchestrator

+- Explicit “round loop in orchestrator

 - Stop conditions

 - GUI: round summaries + convergence charts

 

@@ -42,7 +42,8 @@
 

 ### 9.1 Add explicit rounds

 In `src/pipeline/runProduct.js` (or a new orchestrator wrapper):

-- Round 0: bootstrap sources (url_memory + high-precision search)

+- Round 0: bootstrap identity + canonical sources (url_memory + high-precision search)

+  - goal: lock identity early using Tier‑1 sources before deep-field rounds

 - Round 1..N: targeted discovery for remaining NeedSet

 At end of each round:

 - consensus/validate updates field_state

@@ -51,19 +52,25 @@
 

 ### 9.2 Stop conditions

 Stop when:

-- all identity + publish-gated + required fields:

+- `IdentityLockState.status == 'locked'`, AND

+- all identity + publish-gated + required fields meet gates:

   - confidence >= thresholds

-  - evidence policy met (min_refs, tier)

+  - evidence policy met (min_refs, tier preference)

+  - applicability safe (no critical field backed only by non-applicable / multi-model evidence)

   - conflicts resolved

+  - no remaining `blocked_by_identity` on required/critical fields

 OR

 - max_rounds reached (configurable)

 OR

 - marginal_yield below threshold:

   - last X fetched docs contributed 0 new `evidence_used`

+  - AND no pending identity-lock deficits remain

 

 ### 9.3 Targeted discovery rules

 When NeedSet non-empty:

-- if tier deficit exists: fire Tierâ€‘1 doc_hints first (manual/spec/support)

+- if identity is not locked: fire identity-lock discovery first (Tier‑1 manual/spec/support + SKU/P‑N)

+  - do not chase deep fields until identity is locked (prevents wrong-variant contamination)

+- if tier deficit exists: fire Tier‑1 doc_hints first (manual/spec/support)

 - if conflict remains: fire teardown/lab review doc_hints

 - cap queries and fetched URLs per round

 


--- a/PHASE-10-learning-compounding.md
+++ b/PHASE-10-learning-compounding.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -22,7 +22,7 @@
 

 ---

 

-# Phase 10 â€” Safe learning/compounding (lexicon/anchors/url_memory/domain_yield) gated by acceptance

+# Phase 10 — Safe learning/compounding (lexicon/anchors/url_memory/domain_yield) gated by acceptance

 

 

 ## Goal

@@ -34,7 +34,7 @@
 

 ## Deliverables

 - `LearningUpdater` module

-- GUI â€œLearning Feedâ€ (what changed this run)

+- GUI “Learning Feed (what changed this run)

 - Guardrails for updates (confidence + evidence refs + tier gates)

 

 ## Implementation

@@ -55,17 +55,22 @@
   - store canonical manual/spec/support URLs (with doc_kind and tier)

 - domain_field_yield:

   - increment seen_count and used_count when evidence from domain was used in prime sources

+- identity_alias_memory (optional but high value):

+  - persist validated identity aliases + variant guard terms keyed by `identity_fingerprint`

+  - only after identity is locked (Phase 01) and evidence policy is satisfied

+  - never learn digit mutations; aliases must pass Phase‑02 validation gates

+

 

 ### 10.3 GUI proof

 Learning feed view:

-- â€œAdded anchor X for field Y (from url/snippet_id)â€

-- â€œAdded component Z (accepted, confidence=0.93)â€

-- â€œSaved canonical manual PDF URLâ€

-- â€œDomain yield: rtings.com helped polling_rate +1â€

+- “Added anchor X for field Y (from url/snippet_id)

+- “Added component Z (accepted, confidence=0.93)

+- “Saved canonical manual PDF URL

+- “Domain yield: rtings.com helped polling_rate +1

 

 Proof steps:

 - Run two similar products in same category:

-  - second run should show fewer external searches and faster Tierâ€‘1 hits.

+  - second run should show fewer external searches and faster Tier‑1 hits.

 

 ### 10.4 Feed accepted learning into Studio suggestions (overlooked)

 - Emit Studio suggestion artifacts instead of mutating generated rules in-place:


--- a/README.md
+++ b/README.md
@@ -1,4 +1,4 @@
-﻿# Deep Spec Harvester â€” Phased Implementation Plan (Accuracyâ€‘Max)

+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

 

 This phase file is written as an **implementation prompt for senior software engineers**.

 It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

@@ -6,7 +6,7 @@
 **Guiding principles**

 - Accuracy is the primary objective (95%+ on technical specs).

 - Evidence tiers and confidence gates control *what happens next*.

-- Discovery is needâ€‘driven (missing/low-confidence/conflict fields) â€” no endless key/alias loops.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

 - Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

 - The GUI must prove each phase works before moving to the next.

 

@@ -24,7 +24,7 @@
 

 

 ## Files in this bundle

-- `PHASE-XX-*.md`: one prompt/spec per phase (0â€“11) plus Phase 06B scheduler.

+- `PHASE-XX-*.md`: one prompt/spec per phase (0–11) plus Phase 06B scheduler.

 - `ADDENDUM-field-studio-overlooked-items.md`: phase-mapped Field Studio wiring that is high value for accuracy and optimization.

 - `sql/schema_v1.sql`: SQLite DDL for EvidenceIndexDb (Phase 6) + supporting tables.

 - `docker/docker-compose.observability.yml`: Prometheus + Grafana + Loki + Tempo + (optional) SearXNG.

@@ -32,6 +32,7 @@
 - `prometheus/prometheus.yml`: scrape config (example).

 - `prometheus/alerts.indexlab.yml`: alert rules focused on accuracy + reliability.

 - `grafana/dashboards/*.json`: starter dashboards (IndexLab + Extraction + Sources).

+- `PLAN_CHANGES.patch`: unified diff showing edits in this revision.

 

 ## Phase order (current)

 1. `PHASE-00-indexlab-harness.md`

@@ -55,6 +56,13 @@
 - Phase 09 owns NeedSet deficit signals and convergence decisions.

 - Phase 06B is the single owner of scheduler policy and queue execution.

 

+## Tighten-ups added in this revision (plan-level)

+- **IdentityLockState + applicability gating** so deep fields cannot be accepted from the wrong model/variant.

+- **Phase 04 URL health spec** is now included (it was referenced by other phases and Phase 06B).

+- **EvidenceIndexDb dedupe clarified**: recommend shared content by `content_hash` + per-run instances/links (avoids duplicated chunks/FTS).

+- **snippet_id stability hardened**: snippet IDs should be anchored to `content_hash` and versioned by parser/chunker version.

+- **Scheduler queue alignment**: reconcile `jobs` vs `job_actions`, define `dedupe_key`, and add an explicit TTL policy table.

+

 ## Implemented status updates (2026-02-19)

 - LLM routing controls in GUI now expose model + token cap for every active call lane:

   - plan, triage, fast, reasoning, extract, validate, write


--- a/PHASE-04-url-health-self-healing.md
+++ b/PHASE-04-url-health-self-healing.md
@@ -0,0 +1,159 @@
+# Deep Spec Harvester — Phased Implementation Plan (Accuracy‑Max)

+

+This phase file is written as an **implementation prompt for senior software engineers**.

+It includes: exact deliverables, file touchpoints, schemas/events, test strategy, and **GUI proof**.

+

+**Guiding principles**

+- Accuracy is the primary objective (95%+ on technical specs).

+- Evidence tiers and confidence gates control *what happens next*.

+- Discovery is need‑driven (missing/low-confidence/conflict fields) — no endless key/alias loops.

+- Indexing is deterministic (content_hash dedupe + stable snippet IDs), so results are replayable and auditable.

+- The GUI must prove each phase works before moving to the next.

+

+Repo context (from your `src.zip`):

+- Pipeline orchestrator: `src/pipeline/runProduct.js`

+- Discovery orchestrator: `src/discovery/searchDiscovery.js`

+- Search providers: `src/search/searchProviders.js` (includes SearXNG support)

+- Frontier / URL health: `src/research/frontierDb.js` + `src/research/frontierSqlite.js`

+- Fetchers: `src/fetch/httpFetcher.js`, `src/fetch/playwrightFetcher.js`

+- GUI server: `src/api/guiServer.js` (WS support + review grid)

+

+---

+

+# Phase 04 — URL health + canonicalization + self‑healing signals (frontier owner)

+

+## Goal

+Make URL handling **reliable across runs** by centralizing:

+- URL normalization/canonicalization (dedupe at the right layer)

+- per‑URL and per‑host health tracking (404/410/403/429/captcha/login loops)

+- cooldown/backoff policy inputs

+- explicit **repair trigger signals** consumed by Phase 06B (scheduler)

+

+Phase 04 is the *source of truth* for “is this URL/host safe to try again?” and “should we repair this URL?”.

+

+## Deliverables

+- FrontierDb enhancements:

+  - `normalizeUrl(url)`

+  - `recordUrlOutcome(...)` (writes url_health + bad_url_patterns)

+  - `shouldCooldown(url|host)` / `getHostBudget(host)` (policy inputs)

+- Canonical URL memory:

+  - store best-known canonical URL for a doc_kind (manual/spec/support)

+  - store redirect mappings for stable reuse across runs

+- Repair trigger events (intent only; Phase 06B schedules)

+- GUI: **URL Health** panel + **Canonical URL Memory** panel

+

+## Implementation

+

+### 4.1 URL normalization (must)

+Implement `normalizeUrl(rawUrl)` used everywhere (SERP logging, fetch queue, url_memory):

+

+Rules (deterministic):

+- force lowercase hostname

+- drop common tracking params:

+  - `utm_*`, `gclid`, `fbclid`, `ref`, `cmp`, `mc_*`

+- strip fragments (`#...`)

+- collapse duplicate slashes

+- normalize scheme when safe:

+  - treat `http://` and `https://` as equivalent for dedupe keys, but preserve the final scheme seen after redirects

+- optionally drop “session” query keys by denylist (`sid`, `session`, `phpsessid`) when present

+

+Persist both:

+- `url` (normalized input)

+- `final_url` (after redirects; normalized)

+

+### 4.2 URL + host health tracking (url_health)

+Use `url_health` as a durable store of fetch outcomes across runs (already present in `sql/schema_v1.sql`).

+

+Record these fields on every fetch completion:

+- `last_status` (HTTP code or internal class)

+- `last_ok_ts`, `last_fail_ts`

+- `fail_streak`

+- `cooldown_until`

+- `blocked_reason` (enum: `captcha`, `waf`, `login`, `robots`, `unknown`)

+- `notes_json` (small payload for debug, e.g., redirect chain)

+

+Recommended outcome classification (rules-first):

+- `ok` (200–299 with valid body)

+- `not_found` (404/410)

+- `blocked` (403 with WAF/captcha markers)

+- `rate_limited` (429 or known provider rate messages)

+- `login_wall` (redirect to /login, /signin)

+- `bot_challenge` (captcha / challenge scripts)

+- `bad_content` (HTML is search results, empty shell, or clearly unrelated)

+

+Cooldown policy inputs (Phase 06B owns scheduling; Phase 04 owns signals):

+- if `not_found` repeats: set long cooldown (days) + emit repair trigger

+- if `blocked`/`bot_challenge`: exponential cooldown (minutes → hours) + reduce host budget

+- if `rate_limited`: short cooldown (seconds → minutes) + reduce concurrency temporarily

+

+### 4.3 Bad URL patterns (avoid known traps)

+Maintain `bad_url_patterns` (already in schema) for recurring failure shapes:

+- known “print view” URLs that 404

+- redirect loops

+- “/amp/” mirrors that block bots

+- language/geo gates that return empty shells

+

+On insertion:

+- store `{pattern, reason, evidence_count, last_seen}`

+

+Use in Phase 03 triage and Phase 05 fetch selection:

+- penalize candidates matching known bad patterns

+- optionally rewrite known patterns to their canonical equivalents

+

+### 4.4 Canonical URL memory (url_memory)

+Maintain `url_memory` as “best known stable URL per item/doc_kind”.

+

+Rules:

+- only write to url_memory after **accepted** evidence use (Phase 10 guardrails)

+- store `{item_id, doc_kind, canonical_url, tier, domain, last_verified_ts}`

+- store redirect mapping when a URL consistently redirects to a stable final_url

+

+Read path (Phase 09 Round‑0 bootstrap):

+- prefer canonical manual/spec/support URLs from url_memory before external search

+- if url_memory entry is stale or fails, record the failure in url_health and allow Phase 06B repair loop to act

+

+### 4.5 Repair trigger signals (intent only)

+Phase 04 emits *signals*; Phase 06B schedules jobs.

+

+Trigger conditions:

+- URL has `not_found` (404/410) for `fail_streak >= 2`

+- URL has `login_wall` or persistent `bot_challenge` for `fail_streak >= 2`

+- domain has consistent `blocked` outcomes and needs alternative source routing

+

+Emit an event/row that includes:

+- `source_signal: url_health`

+- `reason: not_found | login_wall | bot_challenge | blocked_domain`

+- `url`, `domain`, `doc_kind_guess`

+- `field_targets` (if known from the query that produced the URL)

+- suggested repair query templates (optional)

+

+### 4.6 Phase boundaries (important)

+- **Phase 05** uses Phase‑04 signals for *in‑run* throttling/escalation (host budget, cooldown).

+- **Phase 06B** uses Phase‑04 signals for *cross‑run* scheduling (repair/refresh cadence).

+- Earlier phases should not invent cooldown policy; they should only record outcomes and consume budgets.

+

+### 4.7 GUI proof

+Add GUI panels:

+

+1) **URL Health**

+- per URL: last outcome, fail_streak, cooldown_until, blocked_reason

+- per host: rolling counts of ok/404/blocked/429

+

+2) **Canonical URL Memory**

+- list saved canonical URLs by doc_kind with last_verified_ts

+- show redirect mappings (url → final_url)

+

+Proof scenarios:

+1. Force a known 404 URL:

+   - url_health shows not_found + increasing fail_streak

+   - repair trigger signal is emitted (visible in GUI events feed)

+2. Force a 429:

+   - host budget drops (concurrency reduced)

+   - cooldown_until is set and respected by Phase 05

+3. Use url_memory bootstrap:

+   - run starts by fetching canonical manual/support links before broad search

+

+## Exit criteria

+- URL normalization is consistent across SERP logging, fetch queue, and url_memory.

+- url_health reliably reflects outcomes and cooldowns, and those cooldowns are visible in the GUI.

+- Repair trigger signals exist and are consumable by Phase 06B without adding policy there.

