file_path,status,needs_implementation,implementation_order,sprint,next_action,audit_basis
src/utils/identityNormalize.js,partial,yes,1,S1-decompose,"EXTRACT: Move normalizeIdentityToken, ambiguityLevelFromFamilyCount, normalizeAmbiguityLevel into src/utils/identityNormalize.js — same function body is duplicated in runProduct.js and needsetEngine.js. Create single source of truth, import in both consumers, delete local copies. TDD: write tests for all three functions before extraction.",Same function body appears at runProduct.js:131-149 and needsetEngine.js:195-209 — pure utility duplication with no test coverage on either copy.
src/pipeline/runOrchestrator.js,partial,yes,2,S1-decompose,EXTRACT: Create src/pipeline/runOrchestrator.js with buildInitialRoundContext (pure function) and RunOrchestrator class (dependency-injected runProductFn). roundContext is orphaned in runProduct.js with no owning module. RunOrchestrator will own round-0 bootstrap; Phase 09 convergence loop will extend it in steps 4-10. TDD: write tests for buildInitialRoundContext and RunOrchestrator before extraction.,roundContext construction is inline in runProduct.js with no owning module and no test path. Needs dedicated module for Phase 09 convergence loop to extend.
src/pipeline/fetchParseWorker.js,partial,yes,3,S1-decompose,"EXTRACT: Create src/pipeline/fetchParseWorker.js — move 9 inline fetch/host-budget helpers (FETCH_OUTCOME_KEYS, classifyFetchOutcome, createFetchOutcomeCounters, createHostBudgetRow, ensureHostBudgetRow, noteHostRetryTs, bumpHostOutcome, applyHostBudgetBackoff, resolveHostBudgetState) out of runProduct.js. TDD: write tests for all 9 helpers before extraction.",9 fetch/host-budget helpers are inline in runProduct.js with no test path. Pure functions suitable for extraction into a dedicated module.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,4,S2-convergence,"PHASE 09 — TDD: Write failing tests for the round controller — test round 0 bootstrap behavior, test round N targeted dispatch, test each stop condition independently (confidence gate, max_rounds, marginal yield), test NeedSet-driven query dispatch",Phase 09 is the core accuracy mechanism and must be TDD-first. No convergence loop production code before failing tests exist.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,5,S2-convergence,PHASE 09: Implement explicit round controller in RunOrchestrator — Round 0 bootstraps from url_memory and high-precision search; Round 1..N computes NeedSet then dispatches targeted discovery only for remaining deficit fields,NeedSet is computed but never acted upon without the loop. This is the single largest accuracy limiter — a single-pass pipeline cannot reach 95% on deep technical specs.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,6,S2-convergence,"PHASE 09: Implement stop conditions — halt when all identity+required fields meet confidence threshold AND evidence policy is satisfied AND conflicts are resolved, OR max_rounds reached, OR marginal_yield is zero (last X fetched docs contributed no new evidence_used)",Stop conditions prevent runaway loops. All three conditions must be independently testable and logged with a stop_reason.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,7,S2-convergence,PHASE 09: Implement NeedSet-driven targeted rediscovery dispatch — tier deficit triggers Tier-1 doc_hints first (manual/spec/support); conflict triggers teardown/lab review hints; cap queries and fetched URLs per round with hard budget,"Targeted dispatch converts NeedSet deficits into new evidence. Without it, NeedSet is a read-only diagnostic. Caps prevent the loop from blowing through API budgets."
implementation/ai-indexing-plans/PHASE-08-extraction-context-wiring.md,partial,yes,8,S2-convergence,"PHASE 08 — ELEVATED: Enforce multi-product identity gate on every evidence unit in extraction context — every evidence row must carry page_product_cluster_id, target_match_score, target_match_passed; reject and downgrade candidates with target_match_passed=false to unknown with identity_uncertain reason. ELEVATED from old position 40 because convergence loop re-extracts across rounds — wrong-product leakage compounds.",Multi-product pages leak non-target specs into extraction without this gate. In a convergence loop bad extraction in round 1 poisons NeedSet for rounds 2-5. This is a hard accuracy correctness requirement.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,9,S2-convergence,"PHASE 09: Add round summary runtime events and run artifact analysis/phase09_rounds.json — emit round_started, round_completed, convergence_stop with NeedSet size, confidence delta, escalation reason, stop reason, and fetch/LLM cost per round",Round observability is required to prove the convergence loop is working. Each round must be auditable independently.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,10,S2-convergence,"PHASE 09: Wire key_migrations.json validation per round — validate all runtime keys against compiled contract before scoring, apply key_migrations mappings, reject unknown keys by default and log metric for each rejection",Key drift across rounds causes silent scoring errors. Per-round validation is the guardrail.
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,11,S3-evidence,"PHASE 06A — TDD: Write failing tests for EvidenceIndexDb — document insert, chunk insert, FTS query, snippet_id generation, dedupe hit detection, and applicability metadata storage",Phase 06A is the foundation for principled retrieval in Phase 07. Currently Phase 07 uses a fallback pool (evidence_pool_fallback_used: true in live proof). TDD first before any implementation.
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,12,S3-evidence,"PHASE 06A: Implement src/index/evidenceIndexDb.js with SQLite lifecycle, documents table, chunks table, facts table, and write APIs — no FTS yet, just the core schema and row persistence","Core EvidenceIndexDb schema must exist before FTS and retrieval can be built on top of it. Keep this step minimal: schema + write + read, no search yet."
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,13,S3-evidence,PHASE 06A: Implement FTS5 virtual table over chunks and facts with ranked query API — replace LIKE fallback with real full-text search over field anchors and value patterns,FTS enables semantic snippet retrieval. Without it Phase 07 cannot find evidence by field anchor proximity — it can only iterate over raw arrays.
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,14,S3-evidence,PHASE 06A: Implement stable snippet_id generation anchored to content_hash + parser version + chunker version — deterministic IDs that survive re-runs on unchanged content,Stable snippet_ids are required for Phase 08 extraction context refs and for Phase 07 prime source lineage. IDs must be deterministic and replayable.
implementation/ai-indexing-plans/PHASE-06B-refetch-scheduler-continuous-repair.md,partial,yes,15,S3-evidence,PHASE 06B: Implement full durable queue state machine (queued/running/done/failed/cooldown) with dedupe_key contract (identity_fingerprint + job_type + scope) and SQLite-backed persistence that survives restarts,Automation queue is partially implemented but not durable. Phase 09 convergence dispatches to this queue — if jobs are lost on restart the convergence loop loses state.
src/scoring/consensusEngine.js,partial,yes,16,S3-evidence,OPTIMIZE/REFACTOR: Implement tiered LLM weight strategy — raise llm_extract score from 0.2 to ~0.6 when best_tier_seen is Tier 1; keep 0.2 for Tier 3+ sources. Add per-field weight override path for fields where deterministic parsing is known to be unreliable,"At 0.2 llm_extract loses to incorrect deterministic values scraped from inconsistent HTML. Tier-1 LLM extraction is more trustworthy than Tier-3 html_table. TDD: write tests proving Tier-1 LLM beats Tier-3 deterministic on conflict, and Tier-3 LLM still loses to Tier-1 deterministic."
implementation/ai-indexing-plans/PHASE-08-extraction-context-wiring.md,partial,yes,17,S3-evidence,"PHASE 08: Add provider-normalized structured output parser — handle non-JSON wrappers (markdown code fences, reasoning prefix/suffix text) consistently across all LLM providers before extraction result parsing",Provider response wrapping causes silent extraction failures when JSON is embedded in prose. Normalization must be applied before any schema validation.
implementation/ai-indexing-plans/PHASE-07-tier-retrieval-prime-sources.md,partial,yes,18,S4-retrieval,"PHASE 07: Apply per-field tier_preference from compiled field rules to retrieval ranking weights — replace fixed global tier weights (tier1=3, tier2=2, tier3=1) with per-field policy lookups",Per-field tier_preference is defined in field rules but currently ignored in retrieval ranking. Applying it improves precision for high-stakes fields like sensor_model and polling_rate.
implementation/ai-indexing-plans/PHASE-07-tier-retrieval-prime-sources.md,partial,yes,19,S4-retrieval,PHASE 07: Add hard identity filter in retriever — suppress snippets from identity-unsafe sources for critical and identity-level fields when identity status is unlocked or conflict,"Without this, extraction for critical fields can be grounded in snippets from wrong-model pages. Identity-unsafe snippets must never become prime sources for critical fields."
implementation/ai-indexing-plans/PHASE-07-tier-retrieval-prime-sources.md,partial,yes,20,S4-retrieval,"PHASE 07: Add retrieval trace objects per field — persist query used, scoring factor breakdown (tier weight, doc_kind alignment, anchor proximity, identity match), and which snippets were selected vs rejected",Retrieval transparency is required for debugging accuracy failures and for Phase 10 to know which anchors improved retrieval.
implementation/ai-indexing-plans/PHASE-07-tier-retrieval-prime-sources.md,partial,yes,21,S4-retrieval,"PHASE 07: Add per-field miss diagnostics (no_anchor, tier_deficit, identity_mismatch) and surface miss reason in GUI retrieval panel with actionable operator hint for each miss type","Miss diagnostics tell operators why a field has no prime sources — directly actionable for adding anchors, fixing sources, or targeting missing Tier-1 docs."
implementation/ai-indexing-plans/PHASE-08-extraction-context-wiring.md,partial,yes,22,S4-retrieval,PHASE 08: Add lane-level prompt and response tracing — persist full prompt assembly and raw LLM response per extraction batch in run artifacts; expose in GUI for debugging accuracy failures at the field level,Field-level accuracy failures are almost impossible to debug without seeing exactly what was in the prompt and what came back. Traces are non-optional for a 95% accuracy target.
implementation/ai-indexing-plans/PHASE-02-searchprofile-alias-planning.md,partial,yes,23,S4-retrieval,"PHASE 02: Upgrade LLM planner output contract — return full structured SearchProfile object with identity_aliases, doc_hint_queries, field_target_queries, and negative_terms, not just a flat query string array. Enforce strict JSON schema validation on the full object","Currently the planner returns query strings only. Structured output unlocks field_target_queries and doc_hint_queries from the LLM path, which Phase 09 needs to dispatch targeted discovery by doc_hint."
implementation/ai-indexing-plans/PHASE-03-provider-search-triage.md,partial,yes,24,S4-retrieval,"PHASE 03: Add SERP applicability fields to candidate rows — identity_match_level, variant_guard_hit, multi_model_hint, other_model_tokens — and surface them in SERP Explorer panel columns with reason badges",Applicability metadata is required for the convergence loop to filter wrong-model candidates before Phase 09 dispatches targeted re-search.
implementation/ai-indexing-plans/PHASE-10-learning-compounding.md,partial,yes,25,S5-learning,"PHASE 10 — TDD: Write failing tests for LearningUpdater acceptance gates — test that updates are rejected when confidence is below threshold, when evidence refs are below min_refs, when field status is not accepted, and when tier criteria are not met",Learning gates must be TDD-proven before any learning store is written. Poisoned learning from ungated updates compounds across runs silently.
implementation/ai-indexing-plans/PHASE-10-learning-compounding.md,partial,yes,26,S5-learning,"PHASE 10: Implement LearningUpdater with strict acceptance gates — only update learning stores when field status=accepted, confidence>=0.85, refs>=min_refs, tier criteria met, and (if component_ref) component review accepted",Learning without acceptance gates risks poisoning. Gates implemented and tested in step 25 must be enforced here without exception.
implementation/ai-indexing-plans/PHASE-10-learning-compounding.md,partial,yes,27,S5-learning,"PHASE 10: Implement four learning stores with decay and expiration — component_lexicon, field_anchors, url_memory (canonical Tier-1 URLs per field), domain_field_yield (seen_count/used_count per domain per field)",Four distinct learning stores enable compounding accuracy improvements. Each must have decay/expiration for stale or low-yield entries to prevent accumulation of bad signals.
implementation/ai-indexing-plans/PHASE-10-learning-compounding.md,partial,yes,28,S5-learning,"PHASE 10: Emit Studio suggestion artifacts instead of mutating rules in-place — write field_rules_suggestions.search_hints.json, anchors.json, known_values.json with evidence references and acceptance stats on every suggestion row","Rollback-safe learning: propose first, require explicit acceptance before writing to active field rules. Never auto-mutate compiled rules."
implementation/ai-indexing-plans/PHASE-01-needset-engine-field-state.md,partial,yes,29,S5-learning,PHASE 01: Implement evidence freshness decay weighting — add timestamp-based confidence decay for evidence rows older than configurable TTL threshold; wire decay factor into effective_confidence computation in NeedSet,Freshness decay is required for Phase 10 learning to correctly deprioritize stale cached evidence from prior runs.
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,30,S5-learning,"PHASE 06A: Add explicit dedupe outcome events into run events — dedupe_hit, reuse_mode, indexed_new — and persist outcomes in run artifacts per source",Dedupe outcomes are currently invisible in the event stream. These events prove the index is reusing content correctly across runs.
implementation/ai-indexing-plans/PHASE-00-indexlab-harness-event-stream.md,partial,yes,31,S5-learning,PHASE 00: Close all remaining event model gaps — audit every event in the spec against what is actually emitted in runtimeBridge.js; add any missing events or missing payload fields; confirm run.json persists all metadata and startup timers,Phase 00 events are the foundation the convergence loop depends on for observability. Missing or malformed events break round tracking.
src/pipeline/consensusPhase.js,partial,yes,32,S5-learning,"EXTRACT: Create src/pipeline/consensusPhase.js with runConsensusWithReducers (dependency-injected) — extract the tight 3-call cluster: runConsensusEngine + applySelectionPolicyReducers + applyListUnionReducers. TDD: write tests before extraction.",runConsensusEngine + two post-consensus reducers form a tight cluster in runProduct.js that can be safely extracted as a single unit.
src/pipeline/learningExportPhase.js,partial,yes,33,S5-learning,"EXTRACT: Create src/pipeline/learningExportPhase.js with runLearningExportPhase (dependency-injected, 7 async functions). TDD: write tests for all 7 functions before extraction.",Learning and export block is a self-contained post-pipeline phase with no interleaving into the main orchestration loop. Safe to extract as a unit.
src/pipeline/runProduct.js,partial,yes,34,S5-learning,"LOC / BLOAT: Audit all inline helper functions over 20 lines in runProduct.js — move each to a dedicated module under src/pipeline/helpers/. Audit all 40+ imports — remove unused. Target: reduce runProduct.js to under 800 lines of orchestration logic only",59k token file is a maintenance and TDD liability. Every inline helper that can be moved improves testability.
implementation/ai-indexing-plans/PHASE-05-parallel-fetch-parse.md,partial,yes,35,S6-scale,"PHASE 05: Implement true bounded multi-pool scheduler with explicit per-lane worker queues (search, fetch, parse, llm) and per-host in-flight caps beyond delay-based pacing",Current concurrency knobs are blunt instruments. True per-lane worker pools with in-flight caps are required before Phase 11 worker controls are meaningful.
implementation/ai-indexing-plans/PHASE-05-parallel-fetch-parse.md,partial,yes,36,S6-scale,"PHASE 05: Implement dual-source no_result resilience — add in-run fallback fetch ladder (Crawlee -> PlaywrightFetcher direct -> HttpFetcher where safe), bounded retry envelope with per-attempt reason codes",Dual-source merged runs block convergence when one source gets no_result with no retry. Fallback ladder prevents degraded merge state from propagating downstream.
implementation/ai-indexing-plans/PHASE-11-workers-runtime-control.md,not_implemented,yes,37,S6-scale,"PHASE 11 — TDD: Write failing tests for worker pool sizing — test that WORKERS_SEARCH, WORKERS_FETCH, WORKERS_PARSE, WORKERS_LLM config values are respected by pool constructors and that per-host backoff still applies under all pool sizes",Worker controls must be tested before they are built. Untested worker scaling hides block-rate regressions.
implementation/ai-indexing-plans/PHASE-11-workers-runtime-control.md,not_implemented,yes,38,S6-scale,"PHASE 11: Implement configurable worker counts per pool in src/config.js and wire into Phase 05 pool constructors — WORKERS_SEARCH, WORKERS_FETCH, WORKERS_PARSE, WORKERS_LLM with sane defaults",Worker sizing is the primary throughput knob. Must be implemented only after convergence correctness is proven by Phase 09.
implementation/ai-indexing-plans/PHASE-11-workers-runtime-control.md,not_implemented,yes,39,S6-scale,"PHASE 11: Add Workers GUI panel — current settings, active and queued per pool, requests/min, 429/blocked rate — with one-click safe drain and live knob adjustment for next run",Worker visibility proves scaling is working without increasing block rate. Drain control is required for safe shutdown under load.
implementation/ai-indexing-plans/PHASE-12-multi-product-batch-automation.md,not_implemented,yes,40,S6-scale,"PHASE 12 — TDD: Write failing tests for batch queue state machine — test queued/running/completed/failed/skipped/stopped transitions, test resume after simulated restart, test that completed items are never re-run without explicit override",Batch state machine must be TDD-proven before build.
implementation/ai-indexing-plans/PHASE-12-multi-product-batch-automation.md,not_implemented,yes,41,S6-scale,"PHASE 12: Implement batch queue state machine (queued/running/completed/failed/skipped/stopped) with durable SQLite-backed persistence, dedupe_key per item, attempt counters, and resumable progress across restarts",Batch execution must survive app restarts without re-running completed items or losing queue state.
implementation/ai-indexing-plans/PHASE-12-multi-product-batch-automation.md,not_implemented,yes,42,S6-scale,"PHASE 12: Implement batch lifecycle APIs — POST /api/v1/indexlab/batch/plan, /start, /pause, /resume, /stop, force-stop and GET /batch/:batchRunId/status, /items — all returning stable IDs and timestamps for replayability",REST control plane is required before any GUI controls can be wired. All endpoints must return stable IDs for audit trail.
implementation/ai-indexing-plans/PHASE-12-multi-product-batch-automation.md,not_implemented,yes,43,S6-scale,"PHASE 12: Implement Batch Run Builder GUI — vertical+horizontal scrolling product grid with checkbox bulk actions, Select All/Clear/Select Brand/Invert/search-filter toolbar, and brand priority controls",Operator UX for large multi-product runs requires fast selection and explicit brand ordering.
implementation/ai-indexing-plans/PHASE-12-multi-product-batch-automation.md,not_implemented,yes,44,S6-scale,"PHASE 12: Add Batch Run Summary panel with live state counters (queued/running/completed/failed), throughput in products/hour, ETA estimate, current product and phase cursor, and top recent failures with short reason",Long-task observability proves batch execution is proceeding correctly.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,45,S2-convergence-gui,"PHASE 09: Add GUI round summary panel — NeedSet size sparkline across rounds, confidence delta cards per round, stop reason badge, escalation reason breakdown, round-level fetch and LLM cost",GUI proof checklist for Phase 09: NeedSet must visibly shrink across rounds and runs must terminate with an explainable stop reason visible in the panel.
implementation/ai-indexing-plans/PHASE-09-convergence-loop-stop-conditions.md,partial,yes,46,S2-convergence-gui,"PHASE 09: End-to-end proof run — execute one product known to have missing deep fields, verify NeedSet shrinks across rounds, stop reason is logged and displayed, identity deficits resolve before deep-field churn begins, total rounds are bounded",Phase 09 is not done until GUI proof is complete and the convergence loop terminates deterministically. This row is the acceptance gate.
implementation/ai-indexing-plans/PHASE-06A-evidence-index-database.md,partial,yes,47,S3-evidence-gui,PHASE 06A: Add inventory and search endpoint in src/api/guiServer.js (GET /api/v1/indexlab/run/:runId/evidence-index) and GUI search box for chunk/fact retrieval proof with match table,"GUI proof: evidence must be searchable by field, value, and quote — and every match must be traceable by snippet_id back to its source URL and page."
implementation/ai-indexing-plans/PHASE-10-learning-compounding.md,partial,yes,48,S5-learning-gui,PHASE 10: Add Learning Feed GUI panel — show exactly what changed per run with source refs and acceptance reason; run two similar products in sequence and verify second run shows fewer external searches and faster Tier-1 hits,"GUI proof for Phase 10: learning is visible, explainable, and demonstrably improves subsequent runs. This is the acceptance gate for Phase 10 completion."
implementation/ai-indexing-plans/PHASE-06B-refetch-scheduler-continuous-repair.md,partial,yes,49,deferred,PHASE 06B: Implement explicit TTL policy table for staleness refresh by domain/doc_kind — wire content_hash unchanged path to skip reparse on unchanged content; add scheduler audit feed for all transitions and retries,"Staleness refresh needs explicit per-domain TTL policy. Deferred — convergence loop handles repair via targeted dispatch in Sprint 2."
implementation/ai-indexing-plans/PHASE-04-url-health-self-healing.md,partial,yes,50,deferred,PHASE 04: Close repair-to-Phase 06B handoff — verify repair_query_enqueued signals are consumed by Phase 06B queue state machine with correct dedupe_key and field_targets; add end-to-end test proving the chain,Phase 04 emits repair signals but Phase 06B scheduler consumption is not proven end-to-end. Deferred — convergence loop handles URL failures via retry rounds.
implementation/ai-indexing-plans/PHASE-04-url-health-self-healing.md,partial,yes,51,deferred,"PHASE 04: Harden domain checklist API — verify all Phase 04 fields (repair_queries, bad_url_patterns, host_budget_score, cooldown_seconds_remaining) are populated from live run data, not placeholders, for every run",Domain checklist is the health dashboard for the URL layer. Deferred — dashboard polish not blocking accuracy.
implementation/ai-indexing-plans/PHASE-03-provider-search-triage.md,partial,yes,52,deferred,"PHASE 03: Add deterministic triage score decomposition per candidate — emit tier bonus, doc_kind alignment bonus, identity bonus, and penalty breakdown so every URL accept/reject decision is fully explainable in the GUI",Score decomposition makes the system auditable. Deferred — auditability improvement not blocking accuracy.
implementation/ai-indexing-plans/PHASE-01-needset-engine-field-state.md,partial,yes,53,deferred,"PHASE 01: Implement row-level snippet timestamp lineage in NeedSet table — surface capture timestamp per evidence row in GUI NeedSet panel, enable sort by evidence age",Timestamp lineage enables decay decisions. Deferred — freshness decay (step 29) is the actionable item; GUI lineage is polish.
implementation/ai-indexing-plans/PHASE-11-workers-runtime-control.md,not_implemented,yes,54,deferred,"PHASE 11: Implement cross-phase knob governance — src/field-rules/capabilities.json as single source of knob truth, CI check that every status=live knob has at least one runtime consumer test, per-run knob-usage telemetry emitted as a run event",Governance prevents dead knobs from accumulating silently. Deferred — useful but not blocking accuracy or throughput.
implementation/ai-indexing-plans/PHASE-08B-visual-asset-capture-proof.md,partial,yes,55,deferred,"PHASE 08B: Implement src/extract/visualAssetCapture.js with target-first image discovery ladder, manifest generation, and sharp-based LLM derivative generation",Visual asset pipeline captures screenshots but lacks target-first discovery and derivative generation. Deferred — visual evidence augments but does not replace text evidence.
implementation/ai-indexing-plans/PHASE-08B-visual-asset-capture-proof.md,partial,yes,56,deferred,"PHASE 08B: Implement visual quality gate and multi-product target-match gate — only quality-passed and target-matched derivatives are eligible for extraction context",Deferred — trash image rejection matters for cost but not for accuracy when text evidence is mandatory.
implementation/ai-indexing-plans/PHASE-08B-visual-asset-capture-proof.md,partial,yes,57,deferred,"PHASE 08B: Wire image_asset_refs into Phase 08 extraction context for ambiguous fields — include visual evidence only when ambiguity level is medium or higher",Deferred — visual evidence is supplementary. Text evidence is the primary accuracy mechanism.
implementation/ai-indexing-plans/PHASE-08B-visual-asset-capture-proof.md,partial,yes,58,deferred,"PHASE 08B: Add Visual Assets GUI panel with live thumbnail strip, preview modal, per-asset download action, quality gate badge, target-match badge",Deferred — GUI polish for visual assets. Not blocking accuracy.
implementation/ai-indexing-plans/parsing-managament/07-scanned-pdf-ocr.md,partial,yes,59,deferred,"PARSING 07: Implement OCR preprocess pass — deskew, denoise, binarize — before Tesseract/PaddleOCR runs; add fixture accuracy suite",Baseline OCR is implemented. Preprocessing affects <5% of evidence surfaces for gaming peripherals.
implementation/ai-indexing-plans/parsing-managament/07-scanned-pdf-ocr.md,partial,yes,60,deferred,PARSING 07: Add GUI fallback-rate proof for PaddleOCR vs Tesseract,Backend selection path exists but is not proven in GUI. Deferred — operator visibility not blocking accuracy.
implementation/ai-indexing-plans/parsing-managament/11-visual-asset-capture.md,partial,yes,61,deferred,"PARSING 11: Implement dedicated Phase 11 visual capture control-plane — per-source capture policy, max-per-source config, capture lifecycle events",Screenshot capture is wired. Full control-plane is optimization. Deferred.
implementation/ai-indexing-plans/parsing-managament/08-image-ocr-extraction.md,not_implemented,yes,62,deferred,"PARSING 08: Implement image OCR worker pipeline — consume Phase 08B/11 visual assets, run OCR per image region",No image OCR pipeline exists. Deferred — depends on Phase 08B visual assets which are also deferred.
implementation/ai-indexing-plans/parsing-managament/09-chart-graph-extraction.md,partial,yes,63,deferred,"PARSING 09: Implement full ordered chart extraction stack — network payload intercept first, config object parsing second, SVG data extraction third, vision fallback",Current coverage is network payloads only. Deferred — niche evidence surface for gaming peripherals.
implementation/ai-indexing-plans/parsing-managament/10-office-mixed-doc-ingestion.md,partial,yes,64,deferred,"PARSING 10: Implement mixed-doc ingestion router — DOCX, XLSX, PPTX unified path",No unified mixed-doc ingestion exists. Deferred — rare for gaming peripherals.
implementation/ai-indexing-plans/parsing-managament/01-static-html-parsing.md,full,no,,complete,COMPLETE — no action required.,Shipped code/tests and runtime integration.
implementation/ai-indexing-plans/parsing-managament/02-dynamic-js-rendered-parsing.md,full,no,,complete,COMPLETE — no action required.,"Shipped with dynamic crawler service, telemetry, and GUI proof."
implementation/ai-indexing-plans/parsing-managament/03-main-article-extraction.md,full,no,,complete,COMPLETE — no action required.,"Shipped with policy overrides, telemetry, and GUI leaderboard."
implementation/ai-indexing-plans/parsing-managament/04-html-spec-table-extraction.md,full,no,,complete,COMPLETE — no action required.,Shipped with table parser V2 behavior and runtime wiring.
implementation/ai-indexing-plans/parsing-managament/05-embedded-json-structured-metadata.md,full,no,,complete,COMPLETE — no action required.,Shipped baseline with sidecar + merger + GUI counters.
implementation/ai-indexing-plans/parsing-managament/06-text-pdf-extraction.md,full,no,,complete,COMPLETE — no action required.,"Shipped baseline with backend router, normalized surfaces, and GUI proof."
