CODEx CLOUD BUILD PROMPT — SPEC HARVESTER (MOUSE CATEGORY, BACKEND-FIRST, S3 INPUT/OUTPUT)
========================================================================================

You are Codex running in a cloud dev environment. Your job is to CREATE a new standalone Node 20 app repo that:
- Reads mouse product “jobs” (one JSON per product) from S3
- Performs backend-first research (network JSON/GraphQL + embedded state + ld+json) from credible sources
- Enforces a strict identity lock gate (≥99% certainty) using provided anchor fields
- Normalizes to a canonical mouse spec schema (field order exactly matches this prompt)
- Outputs JSON (and optional Markdown) to S3, including raw evidence + provenance + run logs
- Supports scheduled/batch execution (run all products for a category/brand on a cadence)

DO NOT ask me follow-up questions. Make reasonable defaults and document them.

----------------------------------------------------------------------------------------
0) REQUIRED ENV VARS (READ FROM PROCESS.ENV)
----------------------------------------------------------------------------------------
AWS_REGION=us-east-2
S3_BUCKET=my-spec-harvester-data
S3_INPUT_PREFIX=specs/inputs
S3_OUTPUT_PREFIX=specs/outputs

Budgets / throttles (defaults ok; make configurable):
MAX_URLS_PER_PRODUCT=8
MAX_PAGES_PER_DOMAIN=2
MAX_RUN_SECONDS=180
MAX_JSON_BYTES=2000000
CONCURRENCY=2
PER_HOST_MIN_DELAY_MS=800
USER_AGENT="Mozilla/5.0 (compatible; EGSpecHarvester/1.0; +https://eggear.com)"

----------------------------------------------------------------------------------------
1) S3 DATA CONTRACT (INPUTS + OUTPUTS) — MUST IMPLEMENT
----------------------------------------------------------------------------------------

INPUTS:
- One JSON file per product, stored at:
  s3://{S3_BUCKET}/{S3_INPUT_PREFIX}/mouse/products/{productId}.json

Example input shape (support additional optional fields):
{
  "productId": "mouse-razer-viper-v3-pro",
  "category": "mouse",
  "identityLock": { "brand":"Razer","model":"Viper V3 Pro","variant":"Wireless","mpn":"","sku":"","gtin":"" },
  "seedUrls": ["https://www.razer.com/gaming-mice/razer-viper-v3-pro"],
  "preferredSources": { "manufacturerHosts":["razer.com"], "retailerHosts":["bestbuy.com","amazon.com"], "reviewHosts":["rtings.com","techpowerup.com","eloshapes.com"] },
  "requirements": {
    "requiredFields": ["identity.brand","identity.model","specs.weight","specs.sensor","specs.polling_rate"],
    "targetCompleteness": 0.9,
    "targetConfidence": 0.8
  },
  "anchors": {
     "weight": "", "material": "", "lngth": "", "width": "", "height": "",
     "form_factor": "", "shape": "", "hump": "", "front_flare": "", "thumb_rest": "",
     "sensor": "", "sensor_brand": "", "polling_rate": "", "dpi": "", "ips": "", "acceleration": "",
     "switch": "", "switch_brand": "", "hot_swappable": "", "side_buttons": "", "middle_buttons": ""
  }
}

NOTES:
- identityLock and anchors are “do not override” values. They are used for wrong-model prevention.
- If an input does not include anchors, still run identity checks, but rely more on manufacturer IDs/SKU/UPC/FCC.

OUTPUTS:
Write to:
s3://{S3_BUCKET}/{S3_OUTPUT_PREFIX}/mouse/{productId}/runs/{runId}/...

and update:
s3://{S3_BUCKET}/{S3_OUTPUT_PREFIX}/mouse/{productId}/latest/...

Output layout (must match):
- raw/pages/{host}/page.html.gz
- raw/pages/{host}/ldjson.json
- raw/pages/{host}/embedded_state.json
- raw/network/{host}/responses.ndjson.gz   (NDJSON of captured JSON/GraphQL responses)
- normalized/mouse.normalized.json         (canonical full output object)
- provenance/fields.provenance.json        (field-level provenance)
- logs/events.jsonl.gz                     (structured events)
- logs/summary.json                        (metrics)
- OPTIONAL: summary/mouse.summary.md        (human summary, safe & factual, no opinions)

Also write:
- latest/normalized.json  (copy of the latest normalized output)
- latest/provenance.json
- latest/summary.json     (compact summary metrics, not MD)
- latest/summary.md       (if MD enabled)

All outputs MUST be private; do not configure public access.

----------------------------------------------------------------------------------------
2) CORE PRINCIPLES (NON-NEGOTIABLE)
----------------------------------------------------------------------------------------
- ACCURACY FIRST. If not confident, output "unk" (or "n/a" if truly not applicable).
- NEVER guess.
- NEVER output opinions, rankings, or game recommendations.
- WRONG-MODEL PREVENTION IS MANDATORY.
- YOU MUST implement the “99% identity certainty gate”:
  If you cannot reach ≥99% certainty for the exact model/variant, write outputs as:
    - logs/summary.json with validated=false and reason="MODEL_AMBIGUITY_ALERT"
    - normalized/mouse.normalized.json should contain only minimal identity fields + quality.notes explaining ambiguity
    - DO NOT fill specs beyond what is locked/anchored; treat as aborted run.

----------------------------------------------------------------------------------------
3) CREDIBLE SOURCE STRATEGY (SMART ORDERING)
----------------------------------------------------------------------------------------
Implement a deterministic “source planner” that tries in this order, and records which tier each source is:

TIER 1 (BEST)
- Official manufacturer product page(s), manuals, spec sheets, support pages
- Instrumented measurement labs/reviews where applicable (e.g., RTINGS)

TIER 2 (GOOD)
- Reputable review outlets with photos/methodology
- Trusted spec databases (e.g., TechPowerUp, EloShapes, mousespecs.org)

TIER 3 (LIMITED)
- Retailer listings / marketplaces (Amazon, BestBuy, etc.) — confirmation only, never sole source

RULES:
- Always try manufacturer first if any seedUrls match manufacturerHosts or if discovery finds them.
- Only use Tier 3 to fill gaps after Tier 1+2 attempts.
- Never accept a value from a page that fails anchor/identity checks.
- Record per-field evidence (which tier, which method).

The planner should:
- prioritize URLs that match manufacturerHosts
- then reviewHosts/databases
- then retailerHosts
- allow discovery only within allowlisted hosts (no broad crawling)

----------------------------------------------------------------------------------------
4) BACKEND-FIRST EXTRACTION (PLAYWRIGHT REQUIRED)
----------------------------------------------------------------------------------------
Use Playwright Chromium and a network recorder that captures:
- Response URL, status, content-type
- If response is JSON-ish, store body (bounded by MAX_JSON_BYTES)
- Mark likely GraphQL responses (endpoint includes "graphql" OR JSON contains {data, errors})

Extraction order per URL:
A) Fetch page content; store HTML snapshot
B) Extract application/ld+json blocks
C) Extract embedded state:
   - __NEXT_DATA__ script (Next.js)
   - window.__NUXT__ (Nuxt)
   - window.__APOLLO_STATE__ (Apollo)
D) Capture network JSON/GraphQL responses and store as NDJSON (raw/network/...)
E) Optional: DOM fallback parsing ONLY if A-D fail to yield needed fields (still must pass identity checks)

Do NOT store cookies or sensitive request headers. Redact auth headers. Do not log request bodies for POST unless needed and safe; prefer response bodies only.

----------------------------------------------------------------------------------------
5) IDENTITY LOCK + ANCHOR MATCH (MOUSE-SPEC RULES)
----------------------------------------------------------------------------------------
Implement the exact wrong-model prevention logic described in the provided spec guidelines:

ANCHOR FIELDS (do not override; used to reject wrong pages):
- weight, material
- lngth, width, height
- form_factor, shape, hump, front_flare, thumb_rest
- sensor, sensor_brand
- polling_rate, dpi, ips, acceleration
- switch, switch_brand
- hot_swappable
- side_buttons, middle_buttons

ANCHOR CONFLICT SEVERITY:
- Sensor or sensor_brand mismatch: ALWAYS MAJOR
- form_factor/shape/hump/front_flare/thumb_rest mismatch: MAJOR
- hot_swappable mismatch: MAJOR
- side_buttons or middle_buttons mismatch: MAJOR (unless clearly reconciled)
- Weight mismatch:
  - ≤ 2 g difference = MINOR
  - > 2 g difference = MAJOR
- Dimensions mismatch:
  - ≤ 1 mm per dimension = MINOR
  - > 1 mm any dimension = MAJOR
- polling_rate max differs: MAJOR
- dpi max differs: MAJOR
- ips/acceleration: MAJOR if class changes or very large difference

IDENTITY GATE (≥99% certainty) — you may proceed to non-anchor fields ONLY if:
A) You found official manufacturer page or official documentation for exact variant and it matches fingerprint.
B) At least TWO additional independent credible sources match the same variant.
C) No unresolved contradictions on identity-critical items (wired/wireless, sensor family, size class, SKU/part# if present).
D) Anchor match checks do not indicate wrong variant.

If identity fails, mark run as MODEL_AMBIGUITY_ALERT, do not output filled specs.

----------------------------------------------------------------------------------------
6) PER-FIELD VALIDATION (3–5 PASSES FOR NON-ANCHOR FIELDS)
----------------------------------------------------------------------------------------
For every NON-ANCHOR field you fill:
- Minimum 3 confirmations from unique root domains that pass identity/anchor checks
- Target 5 confirmations for commonly wrong fields

If <3 credible confirmations:
- Output "unk" (or "n/a" if truly not applicable)
- Record field in logs/summary.json under fields_below_pass_target

Instrumented-only fields (sensor_latency, click_latency, click_force etc.):
- If you cannot get 3 instrumented confirmations, output "unk" (do not borrow random numbers)

----------------------------------------------------------------------------------------
7) CANONICAL OUTPUT SCHEMA (MOUSE) — FIELD ORDER MUST MATCH EXACTLY
----------------------------------------------------------------------------------------
The normalized output must contain (at minimum):
{
  "productId": "...",
  "runId": "...",
  "category": "mouse",
  "identity": { "brand": "...", "model": "...", "base_model": "...", "sku": "...", ... },
  "fields": { "<fieldName>": "<value>" },          // all fields below
  "quality": { "validated": true/false, "confidence": 0..1, "completeness": 0..1, "notes": [] },
  "sources": { "urls": [ ... ], "used": [ ... ] }  // per-url role/tier and anchor-check status
}

FIELD LIST (in order; must be used for TSV export too):
id
brand
model
base_model
category
cardTags
featured
release_date
discontinued
sku
price_range
colors
design
lighting
rgb
connection
connectivity
computer_side_connector
mouse_side_connector
bluetooth
cable_type
paracord
wireless_charging
battery_hours
adjustable_weight
feet_material
coating
honeycomb_frame
silent_clicks
weight
material
lngth
width
height
form_factor
shape
hump
front_flare
thumb_rest
grip
hand_size
mcu
mcu_link
sensor
sensor_brand
sensor_date
sensor_link
sensor_type
flawless_sensor
sensor_latency
sensor_latency_list
shift_latency
polling_rate
dpi
ips
acceleration
lift
lift_settings
motion_sync
hardware_acceleration
smoothing
nvidia_reflex
switch
switch_brand
switch_type
switches_link
hot_swappable
debounce
click_latency
click_latency_list
click_force
encoder
encoder_brand
encoder_link
side_buttons
middle_buttons
programmable_buttons
tilt_scroll_wheel
adjustable_scroll_wheel
onboard_memory
onboard_memory_value
profile_switching

FORMAT RULES:
- Dates: MM/DD/YYYY; if only month/year known → MM/01/YYYY
- Booleans: yes / no / unk (lowercase)
- "n/a" only when truly not applicable (e.g., battery_hours for wired-only)
- Numeric fields: numbers only, no units (g/mm/ms/Hz)
- polling_rate must be descending numbers separated by ", " (example: "8000, 4000, 2000, 1000, 500, 250, 125")
- Lists use ", " separator; multi-color combos use "+" within a variant

Also generate:
- ROW_VALUES_OUTPUT: one TAB-separated line in the exact field order above
Store TSV row in: normalized/mouse.row.tsv (single line) and latest/mouse.row.tsv

----------------------------------------------------------------------------------------
8) IMPLEMENTATION REQUIREMENTS (REPO CONTENTS)
----------------------------------------------------------------------------------------
Create a fully working Node 20 repo with:
- package.json + lockfile
- src/ modules for:
  - s3 client (list inputs, read job json, write artifacts)
  - planner (tiered source ordering)
  - playwright fetcher (html snapshot + recorder)
  - extractors (ldjson, embedded state)
  - network recorder (NDJSON responses, bounded)
  - normalizer (canonical fields map)
  - validator (identity gate, anchor mismatch logic, completeness/confidence)
  - exporter (writes S3 keys; updates latest pointers)
- CLI entrypoints:
  1) node src/cli/run-one.js --s3key <key>
  2) node src/cli/run-batch.js --category mouse [--brand Razer]
- Dockerfile using Playwright base image
- README with:
  - S3 layout
  - env vars
  - IAM least privilege policy
  - run examples (local + docker)
  - “how to add a new category” checklist

Testing:
- unit tests for ld+json extractor, embedded state extractor, anchor mismatch evaluator
- a “dry run” mode that does not hit the network, for CI sanity

----------------------------------------------------------------------------------------
9) COMPLETENESS + CONFIDENCE SCORING
----------------------------------------------------------------------------------------
Completeness:
- Use input requirements.requiredFields if provided, else default to a sensible mouse set.
- completeness = (# required fields that are not "unk"/blank) / (total required fields)

Confidence:
- derived from:
  - tier weight: manufacturer > instrumented review > trusted db > retailer
  - extraction method weight: network_json > embedded_state > ldjson > dom
  - cross-source agreement: more independent domains agreeing increases confidence
  - conflicts: reduce confidence; unresolved conflicts block validation

Also include:
- anchor_fields_present yes/no
- anchor_conflicts list
- fields_below_pass_target list
- new_values_proposed list (if you introduce a value not in known lists)
Store these in logs/summary.json.

----------------------------------------------------------------------------------------
10) RUN THE APP (MANDATORY)
----------------------------------------------------------------------------------------
After generating the repo:
- npm install
- npx playwright install --with-deps chromium (or ensure base image includes it)
- Run a local-mode smoke test (sample job JSON in repo) to produce local outputs
- Do not require real AWS creds for the smoke test (write to ./out/)

Then, document how to run against S3 for real.

----------------------------------------------------------------------------------------
11) IMPORTANT SAFETY / COMPLIANCE
----------------------------------------------------------------------------------------
- Respect site terms and robots where applicable.
- Rate limit per host.
- Avoid broad crawling; only use allowlisted hosts.
- Do not store or leak secrets, cookies, or auth headers.
- Store only what’s needed as evidence (bounded response sizes).

END OF PROMPT
